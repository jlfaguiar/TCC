fastapi==0.115.12
uvicorn[standard]
requests
transformers==4.40.1
torch==2.3.0
pydantic==2.11.4
llama-cpp-python